#!/usr/bin/env python3
"""Qualitative analysis - Show actual SQL generated by base vs expert"""

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import os

BASE_MODEL_PATH = "F:/Node/hivellm/expert/models/Qwen3-0.6B"
EXPERT_PATH = os.path.join(os.path.dirname(__file__), "weights", "qwen3-06b", "final")


def load_models():
    """Load both base and expert models"""
    print("Loading models...\n")
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        device_map="auto",
        torch_dtype=torch.bfloat16,
        trust_remote_code=True
    )
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)
    
    expert_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        device_map="auto",
        torch_dtype=torch.bfloat16,
        trust_remote_code=True
    )
    expert_model = PeftModel.from_pretrained(expert_model, EXPERT_PATH)
    
    return base_model, expert_model, tokenizer


def generate_sql(model, tokenizer, schema, question, max_tokens=400):
    """Generate SQL query from question and schema"""
    prompt = f"""### Instruction: Generate a SQL query for the following question based on the database schema.

### Schema:
{schema}

### Question: {question}

### SQL:
"""
    
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_new_tokens=max_tokens,
            temperature=0.1,
            do_sample=False,
            pad_token_id=tokenizer.eos_token_id
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response


# Test cases para an√°lise qualitativa
test_cases = [
    {
        "name": "Simple JOIN",
        "schema": """CREATE TABLE customers (id INTEGER, name VARCHAR, city VARCHAR);
CREATE TABLE orders (id INTEGER, customer_id INTEGER, amount DECIMAL)""",
        "question": "Show customer names and their total order amounts"
    },
    {
        "name": "GROUP BY with HAVING",
        "schema": "CREATE TABLE sales (product VARCHAR, region VARCHAR, amount DECIMAL)",
        "question": "Which products have total sales over 10000?"
    },
    {
        "name": "Subquery",
        "schema": """CREATE TABLE employees (id INTEGER, name VARCHAR, salary DECIMAL, dept_id INTEGER);
CREATE TABLE departments (id INTEGER, name VARCHAR)""",
        "question": "Find employees earning more than the average salary"
    },
    {
        "name": "LEFT JOIN",
        "schema": """CREATE TABLE authors (id INTEGER, name VARCHAR);
CREATE TABLE books (id INTEGER, title VARCHAR, author_id INTEGER)""",
        "question": "List all authors and their books, including authors without books"
    },
    {
        "name": "Complex aggregation",
        "schema": "CREATE TABLE transactions (date DATE, category VARCHAR, amount DECIMAL, status VARCHAR)",
        "question": "Show total completed and total pending amounts by category"
    },
    {
        "name": "Window function",
        "schema": "CREATE TABLE sales (salesperson VARCHAR, amount DECIMAL, region VARCHAR)",
        "question": "Rank salespeople by amount within each region"
    },
    {
        "name": "Multiple JOINs",
        "schema": """CREATE TABLE students (id INTEGER, name VARCHAR);
CREATE TABLE enrollments (student_id INTEGER, course_id INTEGER, grade DECIMAL);
CREATE TABLE courses (id INTEGER, title VARCHAR, credits INTEGER)""",
        "question": "Show student names, course titles, and grades for all enrollments"
    },
    {
        "name": "Date filtering",
        "schema": "CREATE TABLE events (id INTEGER, name VARCHAR, event_date DATE, attendees INTEGER)",
        "question": "Find events in 2024 with more than 100 attendees"
    },
]


def main():
    base_model, expert_model, tokenizer = load_models()
    
    print("="*80)
    print("QUALITATIVE SQL ANALYSIS - BASE vs EXPERT")
    print("="*80)
    print("\n")
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*80}")
        print(f"TEST {i}/{len(test_cases)}: {test['name']}")
        print(f"{'='*80}\n")
        
        print(f"SCHEMA:\n{test['schema']}\n")
        print(f"QUESTION: {test['question']}\n")
        
        print("-"*80)
        print("BASE MODEL OUTPUT:")
        print("-"*80)
        base_output = generate_sql(base_model, tokenizer, test['schema'], test['question'])
        # Extract just the SQL part
        if "### SQL:" in base_output:
            base_sql = base_output.split("### SQL:")[-1].strip()
            # Limit to first meaningful chunk
            if "\n\n###" in base_sql:
                base_sql = base_sql.split("\n\n###")[0]
            print(base_sql)
        else:
            print(base_output)
        
        print("\n" + "-"*80)
        print("EXPERT MODEL OUTPUT:")
        print("-"*80)
        expert_output = generate_sql(expert_model, tokenizer, test['schema'], test['question'])
        # Extract just the SQL part
        if "### SQL:" in expert_output:
            expert_sql = expert_output.split("### SQL:")[-1].strip()
            # Limit to first meaningful chunk
            if "\n\n###" in expert_sql:
                expert_sql = expert_sql.split("\n\n###")[0]
            print(expert_sql)
        else:
            print(expert_output)
        
        print("\n")


if __name__ == "__main__":
    main()

